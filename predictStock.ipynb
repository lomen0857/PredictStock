{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import os.path\n",
    "import pickle\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "import jsm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.core import common as com\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "def set_span(start=None, end=None, periods=None, freq='D'):\n",
    "    \"\"\" 引数のstart, end, periodsに対して\n",
    "    startとendの時間を返す。\n",
    "\n",
    "    * start, end, periods合わせて2つの引数が指定されていなければエラー\n",
    "    * start, endが指定されていたらそのまま返す\n",
    "    * start, periodsが指定されていたら、endを計算する\n",
    "    * end, periodsが指定されていたら、startを計算する\n",
    "    \"\"\"\n",
    "    if com._count_not_none(start, end, periods) != 2:  # Like a pd.date_range Error\n",
    "        raise ValueError('Must specify two of start, end, or periods')\n",
    "    start = start if start else (pd.Period(end, freq) - periods).start_time\n",
    "    end = end if end else (pd.Period(start, freq) + periods).start_time\n",
    "    return start, end\n",
    "\n",
    "\n",
    "def get_jstock(code, freq='D', start=None, end=None, periods=None):\n",
    "    \"\"\"get Japanese stock data using jsm\n",
    "    Usage:\n",
    "        `get_jstock(6502)`\n",
    "        To get TOSHIBA daily from today back to 30days except holiday.\n",
    "\n",
    "        `get_jstock(6502, 'W', start=pd.Timestamp('2016'), end=pd.Timestamp('2017'))`\n",
    "        To get TOSHIBA weekly from 2016-01-01 to 2017-01-01.\n",
    "\n",
    "        `get_jstock(6502, end=pd.Timestamp('20170201'), periods=50)`\n",
    "        To get TOSHIBA daily from 2017-02-01 back to 50days except holiday.\n",
    "\n",
    "        `get_jstock(6502, 'M', start='first', end='last')`\n",
    "        To get TOSHIBA monthly from 2000-01-01 (the date of start recording) to today.\n",
    "    \"\"\"\n",
    "    # Default args\n",
    "    if com._count_not_none(start, end, periods) == 0:  # All of args is None\n",
    "        end, periods = 'last', 30\n",
    "\n",
    "    # Switch frequency Dayly, Weekly or Monthly\n",
    "    freq_dict = {'D': jsm.DAILY, 'W': jsm.WEEKLY, 'M': jsm.MONTHLY}\n",
    "\n",
    "    # 'first' means the start of recording date\n",
    "    if start == 'first':\n",
    "        data = jsm.Quotes().get_historical_prices(\n",
    "            code, range_type=freq_dict[freq], all=True)\n",
    "        start = [i.date for i in data][-1]\n",
    "    else:\n",
    "        data = None  # Temporaly defined\n",
    "\n",
    "    # 'last' means last weekday (or today)\n",
    "    if end == 'last':\n",
    "        end = pd.datetime.today()\n",
    "\n",
    "    # Return \"start\" and \"end\"\n",
    "    start, end = (x.date() if hasattr(x, 'date')\n",
    "                  else x for x in set_span(start, end, periods, freq))\n",
    "    print('Get data from {} to {}'.format(start, end))\n",
    "\n",
    "    data = jsm.Quotes().get_historical_prices(\n",
    "        code, range_type=freq_dict[freq], start_date=start, end_date=end) if not data else data\n",
    "    df = _convert_dataframe(data)\n",
    "    return df[start:end]\n",
    "\n",
    "\n",
    "def _convert_dataframe(target):\n",
    "    \"\"\"Convert <jsm.pricebase.PriceData> to <pandas.DataFrame>\"\"\"\n",
    "    date = [_.date for _ in target]\n",
    "    open = [_.open for _ in target]\n",
    "    high = [_.high for _ in target]\n",
    "    low = [_.low for _ in target]\n",
    "    close = [_.close for _ in target]\n",
    "    adj_close = [_._adj_close for _ in target]\n",
    "    volume = [_.volume for _ in target]\n",
    "    data = {'Open': open,\n",
    "            'High': high,\n",
    "            'Low': low,\n",
    "            'Close': close,\n",
    "            'Adj Close': adj_close,\n",
    "            'Volume': volume}\n",
    "    columns = *data.keys(),\n",
    "    df = pd.DataFrame(data, index=date, columns=columns).sort_index()\n",
    "    df.index.name = 'Date'\n",
    "    return df\n",
    "\n",
    "def predictStock():\n",
    "\n",
    "    Xcolumns1 = pickle.load(open(\"max_Xcolumns1.sav\",\"rb\"))\n",
    "    Xcolumns2 = pickle.load(open(\"max_Xcolumns2.sav\",\"rb\"))\n",
    "    Xcolumns3 = pickle.load(open(\"max_Xcolumns3.sav\",\"rb\"))\n",
    "\n",
    "    columns_array = ['1321']\n",
    "\n",
    "    for index in range(len(Xcolumns1)):\n",
    "        columns_array.append(Xcolumns1[index][:4])\n",
    "\n",
    "    for index in range(len(Xcolumns2)):\n",
    "        columns_array.append(Xcolumns2[index][:4])\n",
    "\n",
    "    for index in range(len(Xcolumns3)):\n",
    "        columns_array.append(Xcolumns3[index][:4])\n",
    "\n",
    "        \n",
    "    columns_unique_array = list(set(columns_array))\n",
    "    columns_unique_array\n",
    "\n",
    "\n",
    "    #予想用\n",
    "    Xcolumns1 = pickle.load(open(\"max_Xcolumns1.sav\",\"rb\"))\n",
    "    Xcolumns2 = pickle.load(open(\"max_Xcolumns2.sav\",\"rb\"))\n",
    "    Xcolumns3 = pickle.load(open(\"max_Xcolumns3.sav\",\"rb\"))\n",
    "\n",
    "    columns_array = ['1321']\n",
    "\n",
    "    for index in range(len(Xcolumns1)):\n",
    "        columns_array.append(Xcolumns1[index][:4])\n",
    "\n",
    "    for index in range(len(Xcolumns2)):\n",
    "        columns_array.append(Xcolumns2[index][:4])\n",
    "\n",
    "    for index in range(len(Xcolumns3)):\n",
    "        columns_array.append(Xcolumns3[index][:4])\n",
    "\n",
    "        \n",
    "    columns_unique_array = list(set(columns_array))\n",
    "\n",
    "    \n",
    "    today = datetime.today()\n",
    "    twoWeeksAgo = today - timedelta(days=14)\n",
    "    twoWeeksAgo_str = datetime.strftime(twoWeeksAgo,'%Y-%m-%d')\n",
    "\n",
    "    df_1321 = get_jstock(1321,start=pd.Timestamp(twoWeeksAgo_str),end=pd.Timestamp(today))\n",
    "\n",
    "    df_1321.index[-1]\n",
    "    one_str = datetime.strftime(df_1321.index[-1],'%Y-%m-%d')\n",
    "\n",
    "    df_1321.index[-2]\n",
    "    two_str = datetime.strftime(df_1321.index[-2],'%Y-%m-%d')\n",
    "\n",
    "    errorStock_array = []\n",
    "    for code in columns_unique_array :\n",
    "        print(\"start:\" + str(code))\n",
    "        \n",
    "        try:\n",
    "            df_temp = get_jstock(code,start=pd.Timestamp(\"2019-04-12\"),end=pd.Timestamp(\"2019-04-15\"))\n",
    "            df_temp.to_csv('PredictImportETF/' + str(code) + '.csv')\n",
    "            print(\"end:\" + str(code))\n",
    "        except:\n",
    "            df_temp = pd.DataFrame(np.zeros([2,6]), columns=['Open','High','Low','Close','Adj Close','Volume'],index=[two_str,one_str])\n",
    "            df_temp.index.name = 'Date'\n",
    "\n",
    "            df_temp.to_csv('PredictImportETF/' + str(code) + '.csv')\n",
    "            errorStock_array.append(code)\n",
    "            print(\"error\")\n",
    "\n",
    "\n",
    "    for code in columns_unique_array:\n",
    "        print(code)\n",
    "        \n",
    "        path = \"PredictImportETF/\" + str(code) + \".csv\"\n",
    "        \n",
    "        if os.path.exists(path):\n",
    "            temp_df = pd.read_csv(path,engine = \"python\" ,encoding=\"utf8\")\n",
    "        else:\n",
    "            errorStock_array.append(code)\n",
    "            continue\n",
    "            \n",
    "        new_df = pd.DataFrame()\n",
    "        new_df[\"Date\"] = temp_df[\"Date\"]\n",
    "        \n",
    "        #始値\n",
    "        new_df[\"Open\"] = 0\n",
    "        \n",
    "        for dateIndex in temp_df.index:\n",
    "            \n",
    "            #当日の始値\n",
    "            openValue = temp_df.at[dateIndex,\"Open\"]\n",
    "            \n",
    "            new_df.at[dateIndex,\"High\"] = temp_df.at[dateIndex,\"High\"] - openValue\n",
    "            new_df.at[dateIndex,\"Low\"] = temp_df.at[dateIndex,\"Low\"] - openValue\n",
    "            new_df.at[dateIndex,\"Close\"] = temp_df.at[dateIndex,\"Close\"] - openValue\n",
    "            \n",
    "            if dateIndex != 0:\n",
    "                new_df.at[dateIndex,\"Volume\"] = temp_df.at[dateIndex,\"Volume\"] - temp_df.at[dateIndex-1,\"Volume\"]\n",
    "                new_df.at[dateIndex,\"Open\"] = openValue - temp_df.at[dateIndex-1,\"Close\"]\n",
    "                \n",
    "            else:\n",
    "                new_df.at[0,\"Volume\"] = 0\n",
    "        \n",
    "        #csvファイル書き出し\n",
    "        new_df.to_csv(\"PredictStockDataDif/\" + str(code) + \"_dif.csv\")\n",
    "\n",
    "\n",
    "    ETF_df = pd.DataFrame()\n",
    "\n",
    "    for code in columns_unique_array:\n",
    "        \n",
    "        code = str(code)\n",
    "        \n",
    "        temp = pd.DataFrame()\n",
    "        temp = pd.read_csv(\"PredictStockDataDif/\" + code + \"_dif.csv\",encoding=\"utf8\")\n",
    "        \n",
    "        if code == columns_unique_array[0]:\n",
    "            #初回のみETF_dfにindexを設定\n",
    "            ETF_df[\"Date\"] = temp[\"Date\"]\n",
    "            ETF_df = ETF_df.set_index(\"Date\")\n",
    "            \n",
    "        if code ==\"1321\":\n",
    "            for dateIndex in range(0,len(temp.index)-1):\n",
    "                tempDate = temp.at[dateIndex,\"Date\"]\n",
    "                    \n",
    "                tempClose = temp.at[dateIndex+1,\"Close\"]\n",
    "                if tempClose >= 0:\n",
    "                    ETF_df.at[tempDate,\"nextDay_HighLow\"] = 1\n",
    "                else:\n",
    "                    ETF_df.at[tempDate,\"nextDay_HighLow\"] = -1\n",
    "                    \n",
    "        for dateIndex in temp.index:\n",
    "            tempDate = temp.at[dateIndex,\"Date\"]\n",
    "                \n",
    "            ETF_df.at[tempDate,code + \"Open\"] = temp.at[dateIndex,\"Open\"]\n",
    "            ETF_df.at[tempDate,code + \"High\"] = temp.at[dateIndex,\"High\"]\n",
    "            ETF_df.at[tempDate,code + \"Low\"] = temp.at[dateIndex,\"Low\"]\n",
    "            ETF_df.at[tempDate,code + \"Close\"] = temp.at[dateIndex,\"Close\"]\n",
    "            ETF_df.at[tempDate,code + \"Volume\"] = temp.at[dateIndex,\"Volume\"]/10000\n",
    "            \n",
    "    ETF_df1 = ETF_df[Xcolumns1]\n",
    "    ETF_df2 = ETF_df[Xcolumns2]\n",
    "    ETF_df3 = ETF_df[Xcolumns3]\n",
    "\n",
    "    ETF_df1 = ETF_df1.fillna(0)\n",
    "    ETF_df2 = ETF_df2.fillna(0)\n",
    "    ETF_df3 = ETF_df3.fillna(0)\n",
    "\n",
    "    clf1 = pickle.load(open(\"max_clf1.sav\",\"rb\"))\n",
    "    clf1.n_jobs = -1\n",
    "    pred1 = clf1.predict(ETF_df1)\n",
    "\n",
    "    clf2 = pickle.load(open(\"max_clf2.sav\",\"rb\"))\n",
    "    clf2.n_jobs = -1\n",
    "    pred2 = clf2.predict(ETF_df2)\n",
    "\n",
    "    clf3 = pickle.load(open(\"max_clf3.sav\",\"rb\"))\n",
    "    clf3.n_jobs = -1\n",
    "    pred3 = clf3.predict(ETF_df3)\n",
    "\n",
    "    pred = 0\n",
    "\n",
    "    if pred1[1]+pred2[1]+pred3[1] > 0:\n",
    "        pred = 1\n",
    "    else:\n",
    "        pred = -1\n",
    "\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-47cf57157b72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pred3' is not defined"
     ]
    }
   ],
   "source": [
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data from 2019-04-02 to 2019-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuns\\Anaconda3\\lib\\site-packages\\jsm\\util.py:12: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 12 of the file C:\\Users\\shuns\\Anaconda3\\lib\\site-packages\\jsm\\util.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:1330\n",
      "Get data from 2019-04-12 to 2019-04-15\n",
      "end:1330\n",
      "start:1308\n",
      "Get data from 2019-04-12 to 2019-04-15\n",
      "end:1308\n",
      "start:1319\n",
      "Get data from 2019-04-12 to 2019-04-15\n",
      "end:1319\n",
      "start:1306\n",
      "Get data from 2019-04-12 to 2019-04-15\n",
      "end:1306\n",
      "start:1311\n",
      "Get data from 2019-04-12 to 2019-04-15\n",
      "end:1311\n",
      "start:1610\n",
      "Get data from 2019-04-12 to 2019-04-15\n",
      "error\n",
      "start:1612\n",
      "Get data from 2019-04-12 to 2019-04-15\n",
      "end:1612\n",
      "start:1613\n",
      "Get data from 2019-04-12 to 2019-04-15\n",
      "end:1613\n",
      "start:1615\n",
      "Get data from 2019-04-12 to 2019-04-15\n",
      "end:1615\n",
      "start:1320\n",
      "Get data from 2019-04-12 to 2019-04-15\n",
      "end:1320\n",
      "start:1305\n",
      "Get data from 2019-04-12 to 2019-04-15\n",
      "end:1305\n",
      "start:1310\n",
      "Get data from 2019-04-12 to 2019-04-15\n",
      "end:1310\n",
      "start:1321\n",
      "Get data from 2019-04-12 to 2019-04-15\n",
      "end:1321\n",
      "1330\n",
      "1308\n",
      "1319\n",
      "1306\n",
      "1311\n",
      "1610\n",
      "1612\n",
      "1613\n",
      "1615\n",
      "1320\n",
      "1305\n",
      "1310\n",
      "1321\n"
     ]
    }
   ],
   "source": [
    "predict = predictStock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
