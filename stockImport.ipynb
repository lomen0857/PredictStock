{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os.path\n",
    "import jsm\n",
    "\n",
    "from pandas.core import common as com\n",
    "\n",
    "def set_span(start=None, end=None, periods=None, freq='D'):\n",
    "    \"\"\" 引数のstart, end, periodsに対して\n",
    "    startとendの時間を返す。\n",
    "\n",
    "    * start, end, periods合わせて2つの引数が指定されていなければエラー\n",
    "    * start, endが指定されていたらそのまま返す\n",
    "    * start, periodsが指定されていたら、endを計算する\n",
    "    * end, periodsが指定されていたら、startを計算する\n",
    "    \"\"\"\n",
    "    if com._count_not_none(start, end, periods) != 2:  # Like a pd.date_range Error\n",
    "        raise ValueError('Must specify two of start, end, or periods')\n",
    "    start = start if start else (pd.Period(end, freq) - periods).start_time\n",
    "    end = end if end else (pd.Period(start, freq) + periods).start_time\n",
    "    return start, end\n",
    "\n",
    "\n",
    "def get_jstock(code, freq='D', start=None, end=None, periods=None):\n",
    "    \"\"\"get Japanese stock data using jsm\n",
    "    Usage:\n",
    "        `get_jstock(6502)`\n",
    "        To get TOSHIBA daily from today back to 30days except holiday.\n",
    "\n",
    "        `get_jstock(6502, 'W', start=pd.Timestamp('2016'), end=pd.Timestamp('2017'))`\n",
    "        To get TOSHIBA weekly from 2016-01-01 to 2017-01-01.\n",
    "\n",
    "        `get_jstock(6502, end=pd.Timestamp('20170201'), periods=50)`\n",
    "        To get TOSHIBA daily from 2017-02-01 back to 50days except holiday.\n",
    "\n",
    "        `get_jstock(6502, 'M', start='first', end='last')`\n",
    "        To get TOSHIBA monthly from 2000-01-01 (the date of start recording) to today.\n",
    "    \"\"\"\n",
    "    # Default args\n",
    "    if com._count_not_none(start, end, periods) == 0:  # All of args is None\n",
    "        end, periods = 'last', 30\n",
    "\n",
    "    # Switch frequency Dayly, Weekly or Monthly\n",
    "    freq_dict = {'D': jsm.DAILY, 'W': jsm.WEEKLY, 'M': jsm.MONTHLY}\n",
    "\n",
    "    # 'first' means the start of recording date\n",
    "    if start == 'first':\n",
    "        data = jsm.Quotes().get_historical_prices(\n",
    "            code, range_type=freq_dict[freq], all=True)\n",
    "        start = [i.date for i in data][-1]\n",
    "    else:\n",
    "        data = None  # Temporaly defined\n",
    "\n",
    "    # 'last' means last weekday (or today)\n",
    "    if end == 'last':\n",
    "        end = pd.datetime.today()\n",
    "\n",
    "    # Return \"start\" and \"end\"\n",
    "    start, end = (x.date() if hasattr(x, 'date')\n",
    "                  else x for x in set_span(start, end, periods, freq))\n",
    "    print('Get data from {} to {}'.format(start, end))\n",
    "\n",
    "    data = jsm.Quotes().get_historical_prices(\n",
    "        code, range_type=freq_dict[freq], start_date=start, end_date=end) if not data else data\n",
    "    df = _convert_dataframe(data)\n",
    "    return df[start:end]\n",
    "\n",
    "\n",
    "def _convert_dataframe(target):\n",
    "    \"\"\"Convert <jsm.pricebase.PriceData> to <pandas.DataFrame>\"\"\"\n",
    "    date = [_.date for _ in target]\n",
    "    open = [_.open for _ in target]\n",
    "    high = [_.high for _ in target]\n",
    "    low = [_.low for _ in target]\n",
    "    close = [_.close for _ in target]\n",
    "    adj_close = [_._adj_close for _ in target]\n",
    "    volume = [_.volume for _ in target]\n",
    "    data = {'Open': open,\n",
    "            'High': high,\n",
    "            'Low': low,\n",
    "            'Close': close,\n",
    "            'Adj Close': adj_close,\n",
    "            'Volume': volume}\n",
    "    columns = *data.keys(),\n",
    "    df = pd.DataFrame(data, index=date, columns=columns).sort_index()\n",
    "    df.index.name = 'Date'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:6976\n",
      "Get data from 2000-01-01 to 2019-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tamura\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\tamura\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end:6976\n",
      "start:8028\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:8028\n",
      "start:8331\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:8331\n",
      "start:8354\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:8354\n",
      "start:8355\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:8355\n",
      "start:8411\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:8411\n",
      "start:8601\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:8601\n",
      "start:8604\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:8604\n",
      "start:8628\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:8628\n",
      "start:8630\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:8630\n",
      "start:8725\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:8725\n",
      "start:8729\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:8729\n",
      "start:8750\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:8750\n",
      "start:8766\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:8766\n",
      "start:8795\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:8795\n",
      "start:8801\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:8801\n",
      "start:8802\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:8802\n",
      "start:8804\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:8804\n",
      "start:8830\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:8830\n",
      "start:9001\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9001\n",
      "start:9005\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9005\n",
      "start:9007\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9007\n",
      "start:9008\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9008\n",
      "start:9009\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9009\n",
      "start:9020\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9020\n",
      "start:9021\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9021\n",
      "start:9022\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9022\n",
      "start:9062\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9062\n",
      "start:9064\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9064\n",
      "start:9101\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9101\n",
      "start:9104\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9104\n",
      "start:9107\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9107\n",
      "start:9202\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9202\n",
      "start:9301\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9301\n",
      "start:9412\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9412\n",
      "start:9432\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9432\n",
      "start:9433\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9433\n",
      "start:9437\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9437\n",
      "start:9501\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9501\n",
      "start:9502\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9502\n",
      "start:9503\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9503\n",
      "start:9531\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9531\n",
      "start:9532\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9532\n",
      "start:9602\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9602\n",
      "start:9613\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9613\n",
      "start:9681\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9681\n",
      "start:9735\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9735\n",
      "start:9766\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9766\n",
      "start:9983\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9983\n",
      "start:9984\n",
      "Get data from 2000-01-01 to 2019-12-31\n",
      "end:9984\n"
     ]
    }
   ],
   "source": [
    "#学習用\n",
    "df = pd.read_csv('importETF.csv',encoding='utf8')\n",
    "errorStock_array = []\n",
    "\n",
    "#for code in df['code']:\n",
    "for code in tempStockArray:\n",
    "    print(\"start:\" + str(code))\n",
    "    \n",
    "    #csvファイルの存在チェック\n",
    "    #path = 'StockData/' + str(code) + '過去データ.csv'\n",
    "    \n",
    "    try:\n",
    "        df_temp = get_jstock(code,start=pd.Timestamp('20000101'),end=pd.Timestamp('20191231'))\n",
    "        df_temp.to_csv('importETF/' + str(code) + '.csv')\n",
    "        print(\"end:\" + str(code))\n",
    "    except:\n",
    "        errorStock_array.append(code)\n",
    "        print(\"error\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:1623\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1623\n",
      "start:1321\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1321\n",
      "start:1613\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1613\n",
      "start:1320\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1320\n",
      "start:1672\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1672\n",
      "start:1679\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1679\n",
      "start:1546\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1546\n",
      "start:1682\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1682\n",
      "start:1540\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1540\n",
      "start:1551\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1551\n",
      "start:1619\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1619\n",
      "start:1309\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1309\n",
      "start:1343\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1343\n",
      "start:1305\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1305\n",
      "start:1348\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1348\n",
      "start:1622\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1622\n",
      "start:1542\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1542\n",
      "start:1681\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1681\n",
      "start:1631\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1631\n",
      "start:1678\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1678\n",
      "start:1311\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1311\n",
      "start:1329\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1329\n",
      "start:1552\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1552\n",
      "start:1324\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1324\n",
      "start:1629\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1629\n",
      "start:1690\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1690\n",
      "start:1349\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1349\n",
      "start:1323\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1323\n",
      "start:1697\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "error\n",
      "start:1698\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1698\n",
      "start:1545\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1545\n",
      "start:1695\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1695\n",
      "start:1306\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1306\n",
      "start:1326\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1326\n",
      "start:1612\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1612\n",
      "start:1624\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1624\n",
      "start:1683\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "error\n",
      "start:1310\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1310\n",
      "start:1677\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1677\n",
      "start:1680\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1680\n",
      "start:1345\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1345\n",
      "start:1550\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1550\n",
      "start:1627\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1627\n",
      "start:1670\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1670\n",
      "start:1633\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1633\n",
      "start:1671\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1671\n",
      "start:1617\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1617\n",
      "start:1547\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1547\n",
      "start:1632\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1632\n",
      "start:1626\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1626\n",
      "start:1325\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1325\n",
      "start:1620\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1620\n",
      "start:1327\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1327\n",
      "start:1543\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1543\n",
      "start:1696\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1696\n",
      "start:1313\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1313\n",
      "start:1344\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1344\n",
      "start:1615\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1615\n",
      "start:1319\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1319\n",
      "start:1625\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1625\n",
      "start:1541\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1541\n",
      "start:1699\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1699\n",
      "start:1621\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1621\n",
      "start:1346\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1346\n",
      "start:1628\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1628\n",
      "start:1630\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1630\n",
      "start:1308\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1308\n",
      "start:1689\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1689\n",
      "start:1322\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1322\n",
      "start:1618\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1618\n",
      "start:1330\n",
      "Get data from 2019-04-09 to 2019-04-10\n",
      "end:1330\n"
     ]
    }
   ],
   "source": [
    "#予想用\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os.path\n",
    "from sklearn import preprocessing\n",
    "\n",
    "Xcolumns = pickle.load(open(\"max_Xcolumns.sav\",\"rb\"))\n",
    "columns_array = ['1321']\n",
    "\n",
    "for index in range(len(Xcolumns)):\n",
    "    columns_array.append(Xcolumns[index][:4])\n",
    "columns_unique_array = list(set(columns_array))\n",
    "\n",
    "errorStock_array = []\n",
    "today = datetime.today()\n",
    "one = today - timedelta(days=1)\n",
    "one_str = datetime.strftime(one,'%Y-%m-%d')\n",
    "two = today - timedelta(days=2)\n",
    "two_str = datetime.strftime(two,'%Y-%m-%d')\n",
    "\n",
    "for code in columns_unique_array :\n",
    "    print(\"start:\" + str(code))\n",
    "    \n",
    "    try:\n",
    "        df_temp = get_jstock(code,start=pd.Timestamp(two_str),end=pd.Timestamp(one_str))\n",
    "        df_temp.to_csv('PredictImportETF/' + str(code) + '.csv')\n",
    "        print(\"end:\" + str(code))\n",
    "    except:\n",
    "        df_temp = pd.DataFrame(np.zeros([2,6]), columns=['Open','High','Low','Close','Adj Close','Volume'],index=[two_str,one_str])\n",
    "        df_temp.index.name = 'Date'\n",
    "\n",
    "        df_temp.to_csv('PredictImportETF/' + str(code) + '.csv')\n",
    "        errorStock_array.append(code)\n",
    "        print(\"error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1623\n",
      "1321\n",
      "1613\n",
      "1320\n",
      "1672\n",
      "1679\n",
      "1546\n",
      "1682\n",
      "1540\n",
      "1551\n",
      "1619\n",
      "1309\n",
      "1343\n",
      "1305\n",
      "1348\n",
      "1622\n",
      "1542\n",
      "1681\n",
      "1631\n",
      "1678\n",
      "1311\n",
      "1329\n",
      "1552\n",
      "1324\n",
      "1629\n",
      "1690\n",
      "1349\n",
      "1323\n",
      "1697\n",
      "1698\n",
      "1545\n",
      "1695\n",
      "1306\n",
      "1326\n",
      "1612\n",
      "1624\n",
      "1683\n",
      "1310\n",
      "1677\n",
      "1680\n",
      "1345\n",
      "1550\n",
      "1627\n",
      "1670\n",
      "1633\n",
      "1671\n",
      "1617\n",
      "1547\n",
      "1632\n",
      "1626\n",
      "1325\n",
      "1620\n",
      "1327\n",
      "1543\n",
      "1696\n",
      "1313\n",
      "1344\n",
      "1615\n",
      "1319\n",
      "1625\n",
      "1541\n",
      "1699\n",
      "1621\n",
      "1346\n",
      "1628\n",
      "1630\n",
      "1308\n",
      "1689\n",
      "1322\n",
      "1618\n",
      "1330\n"
     ]
    }
   ],
   "source": [
    "for code in columns_unique_array:\n",
    "    print(code)\n",
    "    \n",
    "    path = \"PredictImportETF/\" + str(code) + \".csv\"\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        temp_df = pd.read_csv(path,engine = \"python\" ,encoding=\"utf8\")\n",
    "    else:\n",
    "        errorStock_array.append(code)\n",
    "        continue\n",
    "        \n",
    "    new_df = pd.DataFrame()\n",
    "    new_df[\"Date\"] = temp_df[\"Date\"]\n",
    "    \n",
    "    #始値\n",
    "    new_df[\"Open\"] = 0\n",
    "    \n",
    "    for dateIndex in temp_df.index:\n",
    "        \n",
    "        #当日の始値\n",
    "        openValue = temp_df.at[dateIndex,\"Open\"]\n",
    "        \n",
    "        new_df.at[dateIndex,\"High\"] = temp_df.at[dateIndex,\"High\"] - openValue\n",
    "        new_df.at[dateIndex,\"Low\"] = temp_df.at[dateIndex,\"Low\"] - openValue\n",
    "        new_df.at[dateIndex,\"Close\"] = temp_df.at[dateIndex,\"Close\"] - openValue\n",
    "        \n",
    "        if dateIndex != 0:\n",
    "            new_df.at[dateIndex,\"Volume\"] = temp_df.at[dateIndex,\"Volume\"] - temp_df.at[dateIndex-1,\"Volume\"]\n",
    "            new_df.at[dateIndex,\"Open\"] = openValue - temp_df.at[dateIndex-1,\"Close\"]\n",
    "            \n",
    "        else:\n",
    "            new_df.at[0,\"Volume\"] = 0\n",
    "    \n",
    "    #csvファイル書き出し\n",
    "    new_df.to_csv(\"PredictStockDataDif/\" + str(code) + \"_dif.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETF_df = pd.DataFrame()\n",
    "\n",
    "for code in columns_unique_array:\n",
    "    \n",
    "    code = str(code)\n",
    "    \n",
    "    temp = pd.DataFrame()\n",
    "    temp = pd.read_csv(\"PredictStockDataDif/\" + code + \"_dif.csv\",encoding=\"utf8\")\n",
    "    \n",
    "    if code == columns_unique_array[0]:\n",
    "        #初回のみETF_dfにindexを設定\n",
    "        ETF_df[\"Date\"] = temp[\"Date\"]\n",
    "        ETF_df = ETF_df.set_index(\"Date\")\n",
    "        \n",
    "    if code ==\"1321\":\n",
    "        for dateIndex in range(0,len(temp.index)-1):\n",
    "            tempDate = temp.at[dateIndex,\"Date\"]\n",
    "                \n",
    "            tempClose = temp.at[dateIndex+1,\"Close\"]\n",
    "            if tempClose >= 0:\n",
    "                ETF_df.at[tempDate,\"nextDay_HighLow\"] = 1\n",
    "            else:\n",
    "                ETF_df.at[tempDate,\"nextDay_HighLow\"] = -1\n",
    "                \n",
    "    for dateIndex in temp.index:\n",
    "        tempDate = temp.at[dateIndex,\"Date\"]\n",
    "            \n",
    "        ETF_df.at[tempDate,code + \"Open\"] = temp.at[dateIndex,\"Open\"]\n",
    "        ETF_df.at[tempDate,code + \"High\"] = temp.at[dateIndex,\"High\"]\n",
    "        ETF_df.at[tempDate,code + \"Low\"] = temp.at[dateIndex,\"Low\"]\n",
    "        ETF_df.at[tempDate,code + \"Close\"] = temp.at[dateIndex,\"Close\"]\n",
    "        ETF_df.at[tempDate,code + \"Volume\"] = temp.at[dateIndex,\"Volume\"]/10000\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1697', '1683']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errorStock_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1623Open</th>\n",
       "      <th>1623High</th>\n",
       "      <th>1623Low</th>\n",
       "      <th>1623Close</th>\n",
       "      <th>1623Volume</th>\n",
       "      <th>nextDay_HighLow</th>\n",
       "      <th>1321Open</th>\n",
       "      <th>1321High</th>\n",
       "      <th>1321Low</th>\n",
       "      <th>1321Close</th>\n",
       "      <th>...</th>\n",
       "      <th>1618Open</th>\n",
       "      <th>1618High</th>\n",
       "      <th>1618Low</th>\n",
       "      <th>1618Close</th>\n",
       "      <th>1618Volume</th>\n",
       "      <th>1330Open</th>\n",
       "      <th>1330High</th>\n",
       "      <th>1330Low</th>\n",
       "      <th>1330Close</th>\n",
       "      <th>1330Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-09</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-10</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-0.0092</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2.253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 356 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1623Open  1623High  1623Low  1623Close  1623Volume  \\\n",
       "Date                                                             \n",
       "2019-04-09       0.0       0.0   -170.0     -170.0      0.0000   \n",
       "2019-04-10      70.0       0.0    -30.0      -30.0     -0.0007   \n",
       "\n",
       "            nextDay_HighLow  1321Open  1321High  1321Low  1321Close  \\\n",
       "Date                                                                  \n",
       "2019-04-09              1.0       0.0      50.0    -70.0       10.0   \n",
       "2019-04-10              NaN    -200.0     110.0    -30.0      110.0   \n",
       "\n",
       "               ...      1618Open  1618High  1618Low  1618Close  1618Volume  \\\n",
       "Date           ...                                                           \n",
       "2019-04-09     ...           0.0      50.0    -60.0       50.0      0.0000   \n",
       "2019-04-10     ...        -250.0       0.0    -90.0      -20.0     -0.0092   \n",
       "\n",
       "            1330Open  1330High  1330Low  1330Close  1330Volume  \n",
       "Date                                                            \n",
       "2019-04-09       0.0      60.0    -60.0       30.0       0.000  \n",
       "2019-04-10    -220.0     130.0    -20.0      130.0       2.253  \n",
       "\n",
       "[2 rows x 356 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ETF_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETF_df = ETF_df[Xcolumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETF_df = ETF_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pickle.load(open(\"max_clf.sav\",\"rb\"))\n",
    "pred = clf.predict(ETF_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
